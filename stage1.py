import pandas as pd
import numpy as np
import sklearn
import os
import pandas as pd
import numpy
import numpy as np
import pickle
import sklearn.ensemble as ek
from sklearn import tree, linear_model
from sklearn.feature_selection import SelectFromModel
from sklearn.externals import joblib
from sklearn.pipeline import make_pipeline
from sklearn.model_selection import train_test_split 
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import GaussianNB
import sklearn.ensemble as ske
from sklearn import tree, linear_model
from androguard.misc import *
from numpy import array
from sklearn import tree, linear_model
from sklearn.metrics import confusion_matrix,accuracy_score,roc_auc_score,classification,roc_curve

benign_df = pd.read_csv('./csv/benign.csv')
malign_df = pd.read_csv('./csv/malign.csv')

benign_df['res']=1
malign_df['res']=0

df = pd.concat([benign_df,malign_df])

# dropping the first 2 columns as the first 2 columns are useless
df.drop(df.columns[[0, 0]], axis=1, inplace=True)

X = df.drop(['res'],axis=1)

y = df['res']

print("Actual Dimenions of feature space is ", X.shape)

#Feature Selection
print("==============================================================================")
print("==========================Random forest Classifier============================")
print("==============================================================================")
extratrees = RandomForestClassifier(n_estimators=50).fit(X,y)
model = SelectFromModel(extratrees, prefit=True)
X_new = model.transform(X)
nb_features = X_new.shape[1]

X_train, X_test, y_train, y_test =train_test_split(X_new, y ,test_size=0.3)
features = []
print('%i features identified as important:' % nb_features)

#important features sored
indices = np.argsort(extratrees.feature_importances_)[::-1][:nb_features]
for f in range(nb_features):
    print("%d. feature %s (%f)" % (f + 1, df.columns[2+indices[f]], extratrees.feature_importances_[indices[f]]))


clf = tree.DecisionTreeClassifier(max_depth=10)
clf.fit(X_train, y_train)
score = clf.score(X_test, y_test)
#print("%s : %f %%" % (algo, score*100))
y_pred = clf.predict(X_test)
pred=clf.predict_proba(X_test)   
print("DecisionTreeClassifier: Confusion Matrix: ", confusion_matrix(y_test, y_pred))
print("DecisionTreeClassifier: Accuracy : ", accuracy_score(y_test, y_pred)*100)


