import pandas as pd
import numpy as np
import sklearn
import os
import pandas as pd
import numpy
import numpy as np
import pickle
import sklearn.ensemble as ek
from sklearn import tree, linear_model
from sklearn.feature_selection import SelectFromModel
from sklearn.externals import joblib
from sklearn.pipeline import make_pipeline
from sklearn.model_selection import train_test_split 
from sklearn.ensemble import AdaBoostClassifier,RandomForestClassifier
from sklearn.naive_bayes import GaussianNB
import sklearn.ensemble as ske
from sklearn import tree, linear_model
from androguard.misc import *
from numpy import array



DATASET_PATH = "Dataset/"


benign_df = pd.read_csv('./csv/benign.csv')
malign_df = pd.read_csv('./csv/malign.csv')

benign_df['res']=1
malign_df['res']=0


df = pd.concat([benign_df,malign_df])


# dropping the first 2 columns as the first 2 columns are useless
df.drop(df.columns[[0, 0]], axis=1, inplace=True)

X = df.drop(['res'],axis=1)

y = df['res']

print("Actual Dimenions of feature space is ", X.shape)

#Feature Selection
print("==============================================================================")
print("==========================Random forest Classifier============================")
print("==============================================================================")
extratrees = RandomForestClassifier(n_estimators=50).fit(X,y)
model = SelectFromModel(extratrees, prefit=True)
X_new = model.transform(X)
nb_features = X_new.shape[1]

X_train, X_test, y_train, y_test =train_test_split(X_new, y ,test_size=0.3)
features = []
print('%i features identified as important:' % nb_features)

#important features sored
indices = np.argsort(extratrees.feature_importances_)[::-1][:nb_features]
for f in range(nb_features):
    print("%d. feature %s (%f)" % (f + 1, df.columns[2+indices[f]], extratrees.feature_importances_[indices[f]]))


#AdaBoostClassifier
print("==============================================================================")
print("============================AdaBoostClassifier================================")
print("==============================================================================")
lr = AdaBoostClassifier().fit(X,y)
model = SelectFromModel(lr, prefit=True)
X_new = model.transform(X)
nbfeatures = X_new.shape[1]
#print(nbfeatures)

X_train, X_test, y_train, y_test = train_test_split(X_new, y ,test_size=0.2)

features = []
index = numpy.argsort(lr.feature_importances_)[::-1][:nbfeatures]

for f in range(nbfeatures):
    print("%d. feature %s (%f)" % (f + 1, df.columns[2+index[f]], lr.feature_importances_[index[f]]))


